{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* track the versions of data using dvc\n",
    "* load the raw data into raw_data.csv and save the split data into train.csv/validation.csv/test.csv\n",
    "* update train/validation/test split by choosing different random seed\n",
    "* checkout the first version (before update) using dvc and print the distribution of target variable (number of 0s and number of 1s) in train.csv, validation.csv, and test.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = 'sms_spam_collection/SMSSpamCollection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(FILE_PATH, sep='\\t', names=['label', 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/turing/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/turing/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/turing/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/turing/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['preprocessed_message'] = df['message'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>preprocessed_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>sorry ill call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2863</th>\n",
       "      <td>spam</td>\n",
       "      <td>Adult 18 Content Your video will be with you s...</td>\n",
       "      <td>adult content video shortly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later in meeting.</td>\n",
       "      <td>sorry ill call later meeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2664</th>\n",
       "      <td>spam</td>\n",
       "      <td>8007 FREE for 1st week! No1 Nokia tone 4 ur mo...</td>\n",
       "      <td>free st week nokia tone ur mob every week txt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>spam</td>\n",
       "      <td>09066362231 URGENT! Your mobile No 07xxxxxxxxx...</td>\n",
       "      <td>urgent mobile xxxxxxxxx £ bonus caller prize n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388</th>\n",
       "      <td>ham</td>\n",
       "      <td>NOT MUCH NO FIGHTS. IT WAS A GOOD NITE!!</td>\n",
       "      <td>much fight good nite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>ham</td>\n",
       "      <td>That way transport is less problematic than on...</td>\n",
       "      <td>way transport less problematic sat night way u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>ham</td>\n",
       "      <td>Dont gimme that lip caveboy</td>\n",
       "      <td>dont gim lip caveboy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>ham</td>\n",
       "      <td>SERIOUSLY. TELL HER THOSE EXACT WORDS RIGHT NOW.</td>\n",
       "      <td>seriously tell exact word right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4265</th>\n",
       "      <td>ham</td>\n",
       "      <td>She just broke down a list of reasons why nobo...</td>\n",
       "      <td>broke list reason nobody town cant tell shes s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message  \\\n",
       "2447   ham                             Sorry, I'll call later   \n",
       "2863  spam  Adult 18 Content Your video will be with you s...   \n",
       "57     ham                 Sorry, I'll call later in meeting.   \n",
       "2664  spam  8007 FREE for 1st week! No1 Nokia tone 4 ur mo...   \n",
       "1463  spam  09066362231 URGENT! Your mobile No 07xxxxxxxxx...   \n",
       "5388   ham           NOT MUCH NO FIGHTS. IT WAS A GOOD NITE!!   \n",
       "519    ham  That way transport is less problematic than on...   \n",
       "753    ham                        Dont gimme that lip caveboy   \n",
       "1268   ham   SERIOUSLY. TELL HER THOSE EXACT WORDS RIGHT NOW.   \n",
       "4265   ham  She just broke down a list of reasons why nobo...   \n",
       "\n",
       "                                   preprocessed_message  \n",
       "2447                               sorry ill call later  \n",
       "2863                        adult content video shortly  \n",
       "57                         sorry ill call later meeting  \n",
       "2664  free st week nokia tone ur mob every week txt ...  \n",
       "1463  urgent mobile xxxxxxxxx £ bonus caller prize n...  \n",
       "5388                               much fight good nite  \n",
       "519   way transport less problematic sat night way u...  \n",
       "753                                dont gim lip caveboy  \n",
       "1268                    seriously tell exact word right  \n",
       "4265  broke list reason nobody town cant tell shes s...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].map({'ham': 0, 'spam': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train/validation/test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('processed_data/version_1', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print percentage of each label\n",
    "print(\"Train : \", train_df['label'].value_counts() / len(train_df))\n",
    "print(\"Validation : \", val_df['label'].value_counts() / len(val_df))\n",
    "print(\"Test : \", test_df['label'].value_counts() / len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the splits at train.csv/validation.csv/test.csv\n",
    "train_df.to_csv('processed_data/version_1/train.csv', index=False, sep='\\t')\n",
    "val_df.to_csv('processed_data/version_1/validation.csv', index=False, sep='\\t')\n",
    "test_df.to_csv('processed_data/version_1/test.csv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo.add(\"processed_data/version_1/train.csv\")\n",
    "repo.add(\"processed_data/version_1/validation.csv\")\n",
    "repo.add(\"processed_data/version_1/test.csv\")\n",
    "\n",
    "repo.scm.add([\n",
    "    \"processed_data/version_1/*.csv\",\n",
    "    \".gitignore\"\n",
    "])\n",
    "repo.scm.commit(\"version 1\")\n",
    "repo.scm.tag('v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=43)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.25, random_state=43)\n",
    "\n",
    "print(\"Train : \", train_df['label'].value_counts() / len(train_df))\n",
    "print(\"Validation : \", val_df['label'].value_counts() / len(val_df))\n",
    "print(\"Test : \", test_df['label'].value_counts() / len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('processed_data/version_2', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('processed_data/version_2/train.csv', index=False, sep='\\t')\n",
    "val_df.to_csv('processed_data/version_2/validation.csv', index=False, sep='\\t')\n",
    "test_df.to_csv('processed_data/version_2/test.csv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo.add(\"processed_data/version_2/train.csv\")\n",
    "repo.add(\"processed_data/version_2/validation.csv\")\n",
    "repo.add(\"processed_data/version_2/test.csv\")\n",
    "\n",
    "repo.scm.add([\n",
    "    \"processed_data/version_2/*.csv.dvc\",\n",
    "    \".gitignore\"\n",
    "])\n",
    "repo.scm.commit(\"version 2\")\n",
    "repo.scm.tag('v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load versions and check class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo.scm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('processed_data/train.csv', sep='\\t')\n",
    "val_data = pd.read_csv('processed_data/validation.csv', sep='\\t')\n",
    "test_data = pd.read_csv('processed_data/test.csv', sep='\\t')\n",
    "\n",
    "print(\"Train : \", train_data['label'].value_counts() / len(train_data))\n",
    "print(\"Validation : \", val_data['label'].value_counts() / len(val_data))\n",
    "print(\"Test : \", test_data['label'].value_counts() / len(test_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo.checkout('Version 2')\n",
    "train_data = pd.read_csv('processed_data/train.csv', sep='\\t')\n",
    "val_data = pd.read_csv('processed_data/validation.csv', sep='\\t')\n",
    "test_data = pd.read_csv('processed_data/test.csv', sep='\\t')\n",
    "\n",
    "print(\"Train : \", train_data['label'].value_counts() / len(train_data))\n",
    "print(\"Validation : \", val_data['label'].value_counts() / len(val_data))\n",
    "print(\"Test : \", test_data['label'].value_counts() / len(test_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
